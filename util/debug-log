#!/usr/bin/env python3

import boto3
import json
from munch import *
import os
import sys

logs = [log.lower() for log in sys.argv[1:]]
if len(logs) == 0:
  print('please provide one or more log IDs')
  sys.exit(1)

postfixes = list(set([log.split('-')[1] for log in logs]))

s3 = boto3.resource('s3')

with open('package.json') as f:
  package = json.load(f, object_hook=Munch)
with open('content/s3.json') as f:
  regions = json.load(f, object_hook=Munch)

prefix = regions.bucket
print(prefix)
for region, details in regions.region.items():
  if len(postfixes) > 0 and details.short not in postfixes: continue
  print(region, details)
  merge = {}

  bucket = s3.Bucket(name=f'{prefix}-{details.short}')
  for obj in bucket.objects.all():
    target = os.path.basename(obj.key)

    try:
      parts = os.path.basename(obj.key).split('.')
      if parts[2] in ['json', 'txt'] and int(parts[1]): target = f'{parts[0]}.{parts[2]}'
    except IndexError:
      target = os.path.basename(obj.key)

    if not target in merge: merge[target] = []
    merge[target].append(obj)

if not os.path.exists('logs'): os.makedirs('logs')
for target, partials in merge.items():
  log = os.path.join('logs', target)
  if len([log for log in logs if log in target.lower()]) == 0: continue
  if os.path.exists(log):
    print(f'skipping {target}')
    continue

  print(f'saving {target}')
  with open(log, 'wb') as f:
    for i, partial in enumerate(sorted(partials, key=lambda p: p.key)):
      if len(partials) != 1: print(f'  {i+1}/{len(partials)}')
      f.write(partial.get()['Body'].read())
